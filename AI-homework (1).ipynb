{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader as Dataloader\n",
    "from modelarts.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ma-user/work'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.bash_logout',\n",
       " 'anaconda3',\n",
       " 'modelarts-sdk',\n",
       " 'notebook-exts',\n",
       " '.conda',\n",
       " '.cache',\n",
       " '.jupyter',\n",
       " 'work',\n",
       " 'README',\n",
       " 'env_script',\n",
       " '.pip',\n",
       " '.bashrc',\n",
       " '.profile',\n",
       " '.config',\n",
       " '.npm',\n",
       " '.npmrc',\n",
       " '.yarn',\n",
       " '.modelarts',\n",
       " 'docker_custom_env.py',\n",
       " 'log',\n",
       " '.local',\n",
       " 'notebook-samples-1591414942',\n",
       " 'notebook-samples',\n",
       " '.ipython',\n",
       " 'test_batch',\n",
       " 'data_batch1',\n",
       " 'data_batch2',\n",
       " 'data_batch3',\n",
       " 'data_batch4',\n",
       " 'data_batch5',\n",
       " 'batches.meta']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从OBS上下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.15.1-92d9ed92\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "\n",
    "#下载一个OBS文件夹，从OBS下载至本地Notebook（OBS -> 本地）\n",
    "mox.file.copy_parallel('obs://bucketzc/AI_hk/test/test_batch', '/home/ma-user/test_batch') # 下载测试数据\n",
    "\n",
    "for i in range(1,6):\n",
    "    path = 'obs://bucketzc/AI_hk/train/data_batch_' + str(i)\n",
    "    mox.file.copy_parallel(path, '/home/ma-user/data_batch'+str(i)) # 下载测试数据\n",
    "\n",
    "mox.file.copy_parallel('obs://bucketzc/AI_hk/batches.meta', '/home/ma-user/batches.meta') # 下载label对应的物体名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.bash_logout',\n",
       " 'anaconda3',\n",
       " 'modelarts-sdk',\n",
       " 'notebook-exts',\n",
       " '.conda',\n",
       " '.cache',\n",
       " '.jupyter',\n",
       " 'work',\n",
       " 'README',\n",
       " 'env_script',\n",
       " '.pip',\n",
       " '.bashrc',\n",
       " '.profile',\n",
       " '.config',\n",
       " '.npm',\n",
       " '.npmrc',\n",
       " '.yarn',\n",
       " '.modelarts',\n",
       " 'docker_custom_env.py',\n",
       " 'log',\n",
       " '.local',\n",
       " 'notebook-samples-1591414942',\n",
       " 'notebook-samples',\n",
       " '.ipython',\n",
       " 'test_batch',\n",
       " 'data_batch1',\n",
       " 'data_batch2',\n",
       " 'data_batch3',\n",
       " 'data_batch4',\n",
       " 'data_batch5',\n",
       " 'batches.meta']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据存放再字典中，并使用pickle存放到磁盘上，定义unpickle方法，读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经元网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg19_Net(nn.Module):\n",
    "    def __init__(self,in_img_rgb=3,in_img_size=64,out_class=1000,in_fc_size=25088):\n",
    "        super(vgg19_Net,self).__init__()\n",
    " \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_img_rgb, out_channels=in_img_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_img_size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_img_size,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=0,dilation=1,ceil_mode=False)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=0,dilation=1,ceil_mode=False)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    " \n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv12 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        self.conv13 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv14 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv15 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv16 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    " \n",
    "        self.fc17 = nn.Sequential(\n",
    "            nn.Linear(in_features=in_fc_size, out_features=4096, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    " \n",
    "        self.fc18 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "        self.fc19 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=out_class, bias=True)\n",
    "        )\n",
    " \n",
    "        self.conv_list = [self.conv1,self.conv2,self.conv3,self.conv4,self.conv5,self.conv6,self.conv7,self.conv8,\n",
    "                          self.conv9,self.conv10,self.conv11,self.conv12,self.conv13,self.conv14,self.conv15,self.conv16]\n",
    " \n",
    "        self.fc_list = [self.fc17,self.fc18,self.fc19]\n",
    " \n",
    "    def forward(self, x):\n",
    "         \n",
    "        for conv in self.conv_list:\n",
    "            x = conv(x)\n",
    "             \n",
    "        fc = x.view(x.size(0), -1)\n",
    "         \n",
    "        # 查看全连接层的参数：in_fc_size  的值\n",
    "        # print(\"vgg19_model_fc:\",fc.size(1))\n",
    " \n",
    "        for fc_item in self.fc_list:\n",
    "            fc = fc_item(fc)\n",
    " \n",
    "        return fc\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = vgg19_Net(in_img_rgb=3, in_img_size=32, out_class=10, in_fc_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取和模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用 Adam 作为优化器和 cross entropy 计算损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_num(preds, labels):\n",
    "    correct = preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff272f6cb00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True) # 打开对梯度的追踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg19_Net(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv7): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv8): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv9): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv10): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv11): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv12): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv13): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv14): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv15): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv16): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc17): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc18): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc19): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 181.74766314029694  acc: 0.2949\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 144.9326342344284  acc: 0.4552\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 128.06764221191406  acc: 0.5291\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 119.81898999214172  acc: 0.5752\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 110.16046166419983  acc: 0.6088\n",
      "epoch 1 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 102.07843112945557  acc: 0.6412\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 97.90666604042053  acc: 0.6576\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 90.03115665912628  acc: 0.6867\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 88.07578432559967  acc: 0.694\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 81.60862892866135  acc: 0.718\n",
      "epoch 2 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 74.71271574497223  acc: 0.7412\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 74.88914000988007  acc: 0.7419\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 69.56189960241318  acc: 0.7653\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 67.63961905241013  acc: 0.769\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 61.38023495674133  acc: 0.7922\n",
      "epoch 3 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 58.76179659366608  acc: 0.8014\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 58.51184552907944  acc: 0.8053\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 52.53196322917938  acc: 0.8237\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 53.38614493608475  acc: 0.8237\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 47.173127084970474  acc: 0.8402\n",
      "epoch 4 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 46.10597863793373  acc: 0.8431\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 47.97904297709465  acc: 0.8433\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 43.27666552364826  acc: 0.8556\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 43.611074298620224  acc: 0.861\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 36.85639175772667  acc: 0.8758\n",
      "epoch 5 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 37.22439756989479  acc: 0.8747\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 37.361180782318115  acc: 0.878\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 33.91430839896202  acc: 0.8844\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 33.396409928798676  acc: 0.8893\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 29.03162893652916  acc: 0.9023\n",
      "epoch 6 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 28.470309980213642  acc: 0.9019\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 30.280569449067116  acc: 0.9004\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 27.65404550731182  acc: 0.9081\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 29.49288511276245  acc: 0.9051\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 23.931743122637272  acc: 0.9219\n",
      "epoch 7 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 23.374998077750206  acc: 0.9233\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 23.55405506491661  acc: 0.9226\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 22.529327914118767  acc: 0.9289\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 22.653690733015537  acc: 0.9283\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 19.661933299154043  acc: 0.9355\n",
      "epoch 8 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 20.01562660932541  acc: 0.9365\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 20.6961752474308  acc: 0.9342\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 17.449071813374758  acc: 0.9439\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 19.32125187665224  acc: 0.9391\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 16.874027229845524  acc: 0.945\n",
      "epoch 9 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 16.0587712302804  acc: 0.947\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 15.59198840521276  acc: 0.9501\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 15.566061375662684  acc: 0.9502\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 14.699382895603776  acc: 0.9536\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 14.267010038718581  acc: 0.9525\n",
      "epoch 10 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 13.753687351942062  acc: 0.9534\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 13.540006654337049  acc: 0.9566\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 12.926067871972919  acc: 0.9599\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 13.685778861865401  acc: 0.9549\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 12.087276739999652  acc: 0.9616\n",
      "epoch 11 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 11.328938649967313  acc: 0.9631\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 12.465466633439064  acc: 0.9575\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 12.153905155137181  acc: 0.9628\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 11.198189418762922  acc: 0.9632\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 11.430231660604477  acc: 0.964\n",
      "epoch 12 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 9.48566205240786  acc: 0.969\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 10.999346740543842  acc: 0.9653\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 9.92636682279408  acc: 0.9685\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 10.338684760034084  acc: 0.9652\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 9.495333569124341  acc: 0.969\n",
      "epoch 13 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 9.000438058748841  acc: 0.9725\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 9.917973628267646  acc: 0.9684\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 9.81073356885463  acc: 0.9687\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 9.350046005100012  acc: 0.9691\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 7.760420339182019  acc: 0.9759\n",
      "epoch 14 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 8.360108402557671  acc: 0.9726\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 8.048467749729753  acc: 0.9739\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 7.951296963728964  acc: 0.9739\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 10.121823636814952  acc: 0.9671\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 9.091223946772516  acc: 0.9711\n",
      "epoch 15 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 8.2577256700024  acc: 0.9739\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 9.217814968898892  acc: 0.9689\n",
      "b'training batch 3 of 5'  accessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'training batch 3 of 5'  total_loss: 8.259934726171196  acc: 0.9738\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 8.759199583902955  acc: 0.9709\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 7.238477049395442  acc: 0.9765\n",
      "epoch 16 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 7.109146150760353  acc: 0.9766\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 8.868330870755017  acc: 0.9715\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 7.865737423300743  acc: 0.9774\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 6.572654112242162  acc: 0.979\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 7.012289987877011  acc: 0.9773\n",
      "epoch 17 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 6.2890067412517965  acc: 0.9789\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 7.421666290611029  acc: 0.9749\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 7.090647638309747  acc: 0.9785\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 8.262705622240901  acc: 0.972\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 7.242044276557863  acc: 0.9763\n",
      "epoch 18 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 7.012651355471462  acc: 0.9769\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 7.785480922088027  acc: 0.9754\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 6.8581280913203955  acc: 0.978\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 6.444193489849567  acc: 0.978\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 6.554865583777428  acc: 0.9784\n",
      "epoch 19 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 6.7031175419688225  acc: 0.9775\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 6.296340404544026  acc: 0.9792\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 6.284925204701722  acc: 0.9799\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 7.102597665740177  acc: 0.977\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 6.84581880364567  acc: 0.9793\n",
      "epoch 20 :\n",
      "b'training batch 1 of 5'  accessed\n",
      "b'training batch 1 of 5'  total_loss: 5.689925883430988  acc: 0.982\n",
      "b'training batch 2 of 5'  accessed\n",
      "b'training batch 2 of 5'  total_loss: 4.651829918613657  acc: 0.9844\n",
      "b'training batch 3 of 5'  accessed\n",
      "b'training batch 3 of 5'  total_loss: 5.736751989927143  acc: 0.9813\n",
      "b'training batch 4 of 5'  accessed\n",
      "b'training batch 4 of 5'  total_loss: 6.51785590313375  acc: 0.9791\n",
      "b'training batch 5 of 5'  accessed\n",
      "b'training batch 5 of 5'  total_loss: 6.057098399382085  acc: 0.981\n"
     ]
    }
   ],
   "source": [
    "tt_correct = 0\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "\n",
    "while(tt_correct < 9800): # 定义当网络的准确率在98%时停止训练\n",
    "    print('epoch',epoch,':')\n",
    "    for i in range(1,6):\n",
    "        path = '/home/ma-user/data_batch'+str(i)\n",
    "\n",
    "        data = unpickle(path) # 读取第一组数据\n",
    "        print(data[b'batch_label'],' accessed')\n",
    "        \n",
    "        \n",
    "        images = torch.reshape(torch.tensor(data[b'data'], dtype=torch.float), (10000,3,32,32)) # 从字典中拿出图片数据\n",
    "        labels = torch.tensor(data[b'labels'], dtype=torch.long) # 从字典中拿出label数据\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        images_loader = Dataloader(images, batch_size=100) # 图片迭代器\n",
    "        labels_loader = Dataloader(labels, batch_size=100) # label迭代器\n",
    "        \n",
    "        \n",
    "\n",
    "        # 开始训练模型\n",
    "\n",
    "        tt_loss = 0\n",
    "        tt_correct = 0\n",
    "\n",
    "        for images_batch, labels_batch in zip(images_loader, labels_loader): # 从迭代器中按批取出数据\n",
    "            #images_batch.cuda()\n",
    "            #labels_batch.cuda()\n",
    "            \n",
    "\n",
    "            preds = network(images_batch).to(device) # 计算预测值\n",
    "            loss = F.cross_entropy(preds, labels_batch) # 计算误差\n",
    "            loss.backward() # 误差的前向传播\n",
    "            optimizer.step() # 更新权重\n",
    "\n",
    "            tt_correct += get_correct_num(preds, labels_batch)\n",
    "            tt_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad() # 梯度不累加\n",
    "\n",
    "        print(data[b'batch_label'],' total_loss:',tt_loss,' acc:',tt_correct/10000)\n",
    "    epoch +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'testing batch 1 of 1'  accessed\n",
      "b'testing batch 1 of 1'  total_loss: 7.3472462594509125  acc 0.7771\n"
     ]
    }
   ],
   "source": [
    "test_path = '/home/ma-user/test_batch'\n",
    "\n",
    "test_data = unpickle(test_path) # 读取第一组数据\n",
    "print(test_data[b'batch_label'],' accessed')\n",
    "\n",
    "test_images = torch.reshape(torch.tensor(test_data[b'data'], dtype=torch.float), (10000,3,32,32)) # 从字典中拿出图片数据\n",
    "test_labels = torch.tensor(test_data[b'labels'], dtype=torch.long) # 从字典中拿出label数据\n",
    "\n",
    "test_images = test_images.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_images_loader = Dataloader(test_images, batch_size=100) # 图片迭代器\n",
    "test_labels_loader = Dataloader(test_labels, batch_size=100) # label迭代器\n",
    "\n",
    "size = test_images.size()\n",
    "\n",
    "\n",
    "tt_loss = 0\n",
    "tt_correct = 0\n",
    "\n",
    "for test_images_batch, test_labels_batch in zip(test_images_loader, test_labels_loader): # 从迭代器中按批取出数据\n",
    "    preds = network(test_images_batch) # 计算预测值\n",
    "    \n",
    "    tt_correct += get_correct_num(preds, test_labels_batch)\n",
    "    tt_loss += loss.item()\n",
    "\n",
    "\n",
    "print(test_data[b'batch_label'],' total_loss:',tt_loss,' acc',tt_correct/10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = unpickle('/home/ma-user/batches.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: b'horse'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = test_images_batch[45]\n",
    "test_image.cpu()\n",
    "test_image = torch.tensor(test_image,dtype=torch.int)\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(np.transpose(test_image, (1,2,0)))\n",
    "print('label:',details[b'label_names'][test_labels_batch[45]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
